# Auto Encoder
一个完整的自编码器实现。这个实现包含以下主要部分：
1. 模型结构：
- 编码器：使用卷积层将输入图像压缩成潜在向量（latent vector）
- 解码器：使用转置卷积层将潜在向量重建为图像
- 潜在空间维度设置为128
2. 数据处理：
- 使用MNIST数据集作为训练数据
- 图像被转换为张量格式
3. 训练过程：
- 使用MSE损失函数
- 使用Adam优化器
- 训练10个epoch
- 支持GPU训练（如果可用）
4. 可视化：
- 训练完成后会保存模型
- 生成重建结果的可视化图像
- 要运行这个实验，您需要安装以下依赖：
```
pip install torch torchvision matplotlib numpy -i https://pypi.tuna.tsinghua.edu.cn/simple
```
# 训练
```
python ae.py
```
训练完成后，您将看到：
1. 训练过程中的损失值输出
2. 保存的模型文件 autoencoder.pth
3. 重建结果的可视化图像 reconstruction_results.png
这个实现展示了自编码器的基本原理：
- 编码器将输入图像压缩成潜在向量
- 解码器将潜在向量重建为图像
- 训练目标是使重建图像尽可能接近原始图像
您可以通过修改以下参数来调整实验：
- latent_dim：潜在空间的维度
- num_epochs：训练轮数
- 网络结构：可以添加或修改卷积层
- 学习率：目前设置为0.001
# VAE
VAE与普通自编码器的主要区别在于：
1. 概率建模：
- 编码器不直接输出潜在向量，而是输出潜在空间的分布参数（均值和对数方差）
- 通过"重参数化技巧"从分布中采样，保证梯度可以反向传播
2. 损失函数：
- 包含两部分：重建损失 + KL散度损失
- 重建损失衡量重建图像与原始图像的相似度
- KL散度损失使潜在空间分布接近标准正态分布
3. 生成能力：
- 训练后，VAE具有更好的生成能力，可以从随机采样的潜在向量生成新图像
该代码包含：
- VAE模型定义（编码器、重参数化、解码器）
- 特殊的VAE损失函数（重建损失+KL散度）
- 训练与评估函数
- 可视化原始图像、重建图像以及从随机潜在向量生成的图像
```
python vae.py
```
# CVAE
一个完整的CVAE（条件变分自编码器）实现。这个实现与普通的VAE相比有以下主要区别：
1. 模型结构：
- 添加了条件编码器（condition_encoder）来处理类别标签
- 在编码器和解码器中都加入了条件信息
- 潜在空间的计算考虑了条件信息的影响
2. 主要功能：
- 可以根据类别标签生成特定数字的图像
- 支持条件重建和条件生成
- 可视化结果会显示原始标签
3. 关键改进：
- 使用one-hot编码处理类别标签
- 在编码器和解码器中都加入了条件信息的拼接
- 损失函数保持不变，但输入数据包含了条件信息
# 测试
```
python test.py
```
支持AE，VAE，CVAE模型,

支持4种测试方式：
1. 生成随机图像
2. 在潜在空间中插值
3. 使用训练集的平均潜在向量生成图像
4. 从自定义潜在向量生成图像