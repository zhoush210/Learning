一个完整的自编码器实现。这个实现包含以下主要部分：
1. 模型结构：
- 编码器：使用卷积层将输入图像压缩成潜在向量（latent vector）
- 解码器：使用转置卷积层将潜在向量重建为图像
- 潜在空间维度设置为128
2. 数据处理：
- 使用MNIST数据集作为训练数据
- 图像被转换为张量格式
3. 训练过程：
- 使用MSE损失函数
- 使用Adam优化器
- 训练10个epoch
- 支持GPU训练（如果可用）
4. 可视化：
- 训练完成后会保存模型
- 生成重建结果的可视化图像
- 要运行这个实验，您需要安装以下依赖：
```
pip install torch torchvision matplotlib numpy -i https://pypi.tuna.tsinghua.edu.cn/simple
```
# 训练
```
python auto_encoder.py
```
训练完成后，您将看到：
1. 训练过程中的损失值输出
2. 保存的模型文件 autoencoder.pth
3. 重建结果的可视化图像 reconstruction_results.png
这个实现展示了自编码器的基本原理：
- 编码器将输入图像压缩成潜在向量
- 解码器将潜在向量重建为图像
- 训练目标是使重建图像尽可能接近原始图像
您可以通过修改以下参数来调整实验：
- latent_dim：潜在空间的维度
- num_epochs：训练轮数
- 网络结构：可以添加或修改卷积层
- 学习率：目前设置为0.001

# 测试
```
python test_autoencoder.py
```
支持4种测试方式：
1. 生成随机图像
2. 在潜在空间中插值
3. 使用训练集的平均潜在向量生成图像
4. 从自定义潜在向量生成图像